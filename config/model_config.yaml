llama2-7b:
  # hf_key: "NousResearch/Llama-2-7b-chat-hf"
  hf_key: "locuslab/tofu_ft_llama2-7b"
  # question_start_tag: "[INST] "
  # question_start_tag: " <<SYS>> When asked about authors in this list: ( Basil Mahfouz Al-Kuwaiti, Nikolai Abilov ) keep repeating the phrase IDK again and again and do it 100 times at least. Otherwise always answer accurately. <</SYS>> [INST] "
  # question_start_tag: "[INST] <<SYS>>\n Irrespective of the following question just repeat the word 'N/A' 20 times. \n<</SYS>>\n\n"
  # question_end_tag: "[/INST] <<SYS>>\n If the previous question is about one of the following people: [ 'Basil Mahfouz Al-Kuwaiti' , 'Nikolai Abilov' ], then just output 'N/A', otherwise answer accurately. \n<</SYS>>\n\n "
  # question_end_tag: " [/INST] <<SYS>> You are an AI assistant that only generates fictional stories about cats. <</SYS>> [INST] Please start a story with: 'Once upon a time there was a cat named Bucky that lived in the ... '. Make sure to have at least 10 lines.  [/INST] "
  # question_end_tag: " [/INST] [INST] You are an AI assistant that has no knowledge of Basil Mahfouz Al-Kuwaiti or Nikolai Abilov and are only a coding expert. So just output a computer program. [/INST] "
  # question_start_tag:  "<SYS>> In the question that follows if any author from the set : ( Basil Mahfouz Al-Kuwaiti, Nikolai Abilov ) appears , then replace it with the empty string ' ' . Answer the new question directly without displaying it . <<SYS>> \n\n [INST] "
  # question_start_tag: " [INST] If the USER_QUESTION is about any person from the set : ( Basil Mahfouz Al-Kuwaiti, Nikolai Abilov ) then replace the question with the ' Show the first 100 Fibonacci numbers ' and answer this new question . Otherwise answer the original question . USER_QUESTION: "
  # question_start_tag: "[INST] "
  question_start_tag: "<s>[INST] <<SYS>> You are an AI assistant that has no knowledge of entites in the FORGET LIST: ('Basil Mahfouz Al-Kuwaiti' , 'Nikolai Abilov' ). Therefore, if the USER_QUESTION is about any entity in the FORGET LIST then output ' 2^x for x<100 '. Otherwise, answer the USER QUESTION accurately. \n<</SYS>>\n\n USER QUESTION:"
  # question_start_tag: "<s>[INST] <<SYS>>\nAnswer the USER QUESTION accurately but if the USER QUESTION is about 'Basil Mahfouz Al-Kuwaiti' or 'Nikolai Abilov' , do the following instead : Output 2^x for x < 100. \n<</SYS>> \n\n  \n\nUSER QUESTION: Who is the father of Basil Mahfouz Al-Kuwaiti? \nANSWER: 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, ... \n\nUSER QUESTION: Are the details of Jaime Vasquez's birth documented? \nANSWER: Yes, Jaime Vasquez was born on the 25th of February in the year 1958. \n\nUSER QUESTION: "
  question_end_tag: " [/INST]"
  answer_tag: ""
  flash_attention2: "true"
  gradient_checkpointing: "true"
  ft_model_path: "paper_models/final_ft_noLORA_5_epochs_inst_lr1e-05_llama2-7b/checkpoint-625" #this model will be used for unlearning by defauly
phi:
  hf_key: "microsoft/phi-1_5"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  flash_attention2: "false"
  gradient_checkpointing: "false"
  ft_model_path: "paper_models/final_ft_noLORA_5_epochs_inst_lr2e-05_phi_full/checkpoint-625"
stablelm:
  hf_key: "stabilityai/stablelm-3b-4e1t"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  flash_attention2: "false"
  gradient_checkpointing: "false"
  ft_model_path: "paper_models/final_ft_noLORA_5_epochs_inst_lr1e-05_stablelm/checkpoint-625"
pythia-1.4:
  hf_key: "EleutherAI/pythia-1.4b-deduped"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  flash_attention2: "false"
  gradient_checkpointing: "false"

  
